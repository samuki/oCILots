TRAIN_PATH: 'data/trainingBig'
VAL_PATH: 'data/validation'
TEST_PATH: 'data/test/images'


PATCH_SIZE: 16  # pixels per side of square patches
VAL_SIZE: 10  # size of the validation set (number of images)
CUTOFF: 0.25  # minimum average brightness for a mask patch to be classified as containing road
BATCH_SIZE: 4
HEIGHT: 400
WIDTH: 400
MINHEIGHT: 384
MINWIDTH: 384

# gradient accumulation which allows for larger batch sizes
# the effective batch size is BATCH_SIZE*GRAD_ACCUM
GRAD_ACCUM: 1

# this add random crops of size HEIGHT x WIDTH and augmentations with p_augement. View dataset.__training_augmentation() for details


# Define whether input data should be augmented or not
# to enable cropping we set augmentation=True but p_augment=0âˆš
USE_AUGMENTATION: True

# define whether the data should be normalized or not
USE_NORMALIZATION: True

# when using the augmented Dataset we need to specify the probability to apply augmentations to an image
p_augment: 0.6


###################################################### MODEL & TRAINING ######################################################

RANDOM_SEED: 42

# model
#MODEL: UNet().to(config.DEVICE)
#MODEL = SwinTransformerPretrained().to(DEVICE)
#MODEL: MaskformerPretrained().to(config.DEVICE)
#model = LRSRModel().to(DEVICE)
MODEL: SegFormerPretrained().to(config.DEVICE)

# load ckpt to fine-tune
LOAD_CKTP: False
#CKPT_PATH: "results/28072022_17:51:49"

EPOCHS: 150
 
LOSS: torch.nn.MSELoss()


# optimizer 
OPTIMIZER:  torch.optim.AdamW(config.MODEL.parameters())
#OPTIMIZER: torch.optim.Adam(config.MODEL.parameters())
#OPTIMIZER = torch.optim.SGD(MODEL.parameters(), lr=0.01, momentum=0.9)

# custom learning rate scheduler
use_custom_lr_scheduler: False
start_lr: 0.0001
warm_up_epochs: 0

# save best model, choose option in ['val_loss', 'val_acc', 'val_patch_acc, val_f1_patch_acc']
save_best_metric: 'val_f1_patch_acc'
minimize_metric: False
