TRAIN_PATH: 'data/training'
VAL_PATH: 'data/validation'
TEST_PATH: 'data/test/images'


PATCH_SIZE: 16  # pixels per side of square patches
VAL_SIZE: 10  # size of the validation set (number of images)
CUTOFF: 0.25  # minimum average brightness for a mask patch to be classified as containing road
BATCH_SIZE: 4
HEIGHT: 384
WIDTH: 384
MINHEIGHT: 384
MINWIDTH: 384

# gradient accumulation which allows for larger batch sizes
# the effective batch size is BATCH_SIZE*GRAD_ACCUM
GRAD_ACCUM: 1

# this add random crops of size HEIGHT x WIDTH and augmentations with p_augement. View dataset.__training_augmentation() for details


# Define whether input data should be augmented or not
USE_AUGMENTATION: True

# define whether the data should be normalized or not
USE_NORMALIZATION: True

# when using the augmented Dataset we need to specify the probability to apply augmentations to an image
p_augment: 0.25


###################################################### MODEL & TRAINING ######################################################

RANDOM_SEED: 42

# model
MODEL: UNet().to(config.DEVICE)

# load ckpt to fine-tune
LOAD_CKTP: False
CKPT_PATH: ""

EPOCHS: 100

LOSS: torch.nn.BCELoss()


# optimizer 
OPTIMIZER: torch.optim.AdamW(config.MODEL.parameters(), lr=0.001)


# custom learning rate scheduler
use_custom_lr_scheduler: False
start_lr: 0.3
warm_up_epochs: 0

# save best model, choose option in ['val_loss', 'val_acc', 'val_patch_acc']
save_best_metric: 'val_f1_patch_acc'
minimize_metric: False